{
  "module": {
    "id": "01",
    "title": "Introduction to Digital Image Processing",
    "course": "CMSC 178",
    "institution": "University of the Philippines - Cebu",
    "estimatedDuration": "45 minutes",
    "prerequisites": [
      "Basic programming",
      "Linear algebra fundamentals"
    ]
  },
  "slides": [
    {
      "id": 1,
      "title": "What is Digital Image Processing?",
      "readingTime": "2 min",
      "content": "<div class=\"key-point\">Digital Image Processing (DIP) is the use of computer algorithms to perform image processing on <strong>digital images</strong>.</div><div class=\"two-column\"><div class=\"column\"><h4>Input</h4><ul><li>Digital image(s)</li><li>2D array of pixel values</li></ul></div><div class=\"column\"><h4>Output</h4><ul><li>Enhanced image</li><li>Extracted information</li><li>Measurements or features</li></ul></div></div>",
      "hasVisualization": false,
      "knowledgeCheck": null
    },
    {
      "id": 2,
      "title": "Real-World Applications",
      "readingTime": "2 min",
      "content": "<div class=\"highlight\"><h4>Where is DIP Used?</h4><ul><li><strong>Medical Imaging:</strong> CT scans, MRI, X-rays</li><li><strong>Satellite & Remote Sensing:</strong> Weather, agriculture, mapping</li><li><strong>Autonomous Vehicles:</strong> Object detection, lane recognition</li><li><strong>Biometrics:</strong> Face recognition, fingerprint analysis</li><li><strong>Social Media:</strong> Filters, enhancement, compression</li></ul></div><img src=\"/static/images/courses/cmsc178ip/module-01/applications_collage_real.png\" alt=\"DIP Applications\" style=\"max-width: 100%; border-radius: 8px; margin-top: 1rem;\">",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 3,
      "title": "Learning Objectives",
      "readingTime": "1 min",
      "content": "<div class=\"highlight\"><h4>By the end of this module, you will:</h4><ol><li>Explain how digital images are represented as 2D arrays</li><li>Describe the processes of <strong>sampling</strong> and <strong>quantization</strong></li><li>Distinguish between binary, grayscale, and color images</li><li>Understand <strong>RGB</strong> and <strong>HSV</strong> color models</li><li>Calculate memory requirements for different image types</li></ol></div>",
      "hasVisualization": false,
      "knowledgeCheck": null
    },
    {
      "id": 4,
      "title": "Image as a 2D Function",
      "readingTime": "3 min",
      "content": "<div class=\"definition\"><strong>Continuous Image:</strong> A function $f(x, y)$ where $x, y$ are spatial coordinates and $f$ is the intensity (brightness).</div><div class=\"definition\"><strong>Digital Image:</strong> A discrete function $f[m, n]$ where indices $m, n$ are integers.</div><div class=\"math-block\">$$f: \\mathbb{Z}^2 \\rightarrow \\{0, 1, 2, ..., L-1\\}$$</div><div class=\"two-column\"><div class=\"column\"><h4>Continuous</h4><ul><li>$x, y \\in \\mathbb{R}$</li><li>Infinite precision</li><li>Real-world scene</li></ul></div><div class=\"column\"><h4>Discrete</h4><ul><li>$m \\in \\{0, ..., M-1\\}$</li><li>$n \\in \\{0, ..., N-1\\}$</li><li>Finite pixels</li></ul></div></div>",
      "hasVisualization": false,
      "knowledgeCheck": {
        "question": "What does f(x,y) represent in image processing?",
        "answer": "f(x,y) represents the intensity (brightness) value at the spatial coordinates (x,y). In a continuous image, x and y are real numbers; in a digital image, they are discrete indices."
      }
    },
    {
      "id": 5,
      "title": "From Continuous to Discrete",
      "readingTime": "2 min",
      "content": "<div class=\"key-point\">Converting a continuous image to digital form requires two processes: <strong>Sampling</strong> and <strong>Quantization</strong>.</div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/pixel_grid_visualization.svg\" alt=\"Pixel Grid\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"definition\"><strong>Pixel:</strong> Picture element — the smallest addressable unit in a digital image.</div>",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 6,
      "title": "Image Coordinate System",
      "readingTime": "2 min",
      "content": "<div class=\"highlight\"><h4>Standard Convention</h4><ul><li><strong>Origin:</strong> Top-left corner at (0, 0)</li><li><strong>x-axis:</strong> Increases to the right (columns)</li><li><strong>y-axis:</strong> Increases downward (rows)</li></ul></div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/coordinate_system.svg\" alt=\"Coordinate System\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"definition\"><strong>Matrix notation:</strong> $I[i, j]$ where $i$ = row, $j$ = column</div>",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 7,
      "title": "Spatial Sampling",
      "readingTime": "3 min",
      "content": "<div class=\"definition\"><strong>Sampling:</strong> The process of converting continuous spatial coordinates into discrete pixel locations.</div><div class=\"two-column\"><div class=\"column\"><h4>Higher Sampling Rate</h4><ul><li>More pixels</li><li>More detail preserved</li><li>Larger file size</li></ul></div><div class=\"column\"><h4>Lower Sampling Rate</h4><ul><li>Fewer pixels</li><li>Loss of detail</li><li>Aliasing artifacts</li></ul></div></div><div class=\"math-block\">$$\\text{Nyquist Theorem: } f_s \\geq 2 \\cdot f_{max}$$</div><div class=\"key-point\">The sampling rate must be at least twice the highest frequency in the image to avoid aliasing.</div>",
      "hasVisualization": false,
      "knowledgeCheck": {
        "question": "What happens if we sample below the Nyquist rate?",
        "answer": "Aliasing occurs — high-frequency details appear as false low-frequency patterns (jagged edges, moiré patterns). Information is permanently lost and cannot be recovered."
      }
    },
    {
      "id": 8,
      "title": "Effect of Sampling Rate",
      "readingTime": "2 min",
      "content": "<div class=\"key-point\">Lower sampling rates result in fewer pixels and loss of fine detail.</div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/sampling_demonstration.svg\" alt=\"Sampling Demonstration\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"highlight\"><h4>Observations</h4><ul><li><strong>512×512:</strong> Full detail (262,144 pixels)</li><li><strong>128×128:</strong> Some detail loss (16,384 pixels)</li><li><strong>32×32:</strong> Heavy pixelation (1,024 pixels)</li></ul></div>",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 9,
      "title": "Spatial Resolution",
      "readingTime": "2 min",
      "content": "<div class=\"definition\"><strong>Spatial Resolution:</strong> The number of pixels per unit length (e.g., pixels per inch, PPI).</div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/resolution_comparison.svg\" alt=\"Resolution Comparison\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"highlight\"><h4>Common Resolutions</h4><ul><li><strong>VGA:</strong> 640 × 480 (307,200 pixels)</li><li><strong>Full HD:</strong> 1920 × 1080 (2.07 megapixels)</li><li><strong>4K:</strong> 3840 × 2160 (8.29 megapixels)</li></ul></div>",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 10,
      "title": "Intensity Quantization",
      "readingTime": "3 min",
      "content": "<div class=\"definition\"><strong>Quantization:</strong> The process of mapping continuous intensity values to discrete levels.</div><div class=\"math-block\">$$L = 2^k \\text{ levels, where } k = \\text{bits per pixel}$$</div><div class=\"two-column\"><div class=\"column\"><h4>Common Bit Depths</h4><ul><li><strong>1-bit:</strong> 2 levels (binary)</li><li><strong>4-bit:</strong> 16 levels</li><li><strong>8-bit:</strong> 256 levels</li><li><strong>16-bit:</strong> 65,536 levels</li></ul></div><div class=\"column\"><h4>Effects</h4><ul><li>Fewer levels → visible banding</li><li>More levels → smoother gradients</li><li>Trade-off: quality vs. storage</li></ul></div></div>",
      "hasVisualization": false,
      "knowledgeCheck": null
    },
    {
      "id": 11,
      "title": "Effect of Quantization",
      "readingTime": "2 min",
      "content": "<div class=\"key-point\">Fewer bits per pixel results in visible <strong>banding</strong> (posterization effect).</div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/quantization_effects.svg\" alt=\"Quantization Effects\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"highlight\"><h4>Observations</h4><ul><li><strong>8-bit:</strong> 256 levels — smooth gradients</li><li><strong>4-bit:</strong> 16 levels — slight banding</li><li><strong>2-bit:</strong> 4 levels — obvious posterization</li><li><strong>1-bit:</strong> 2 levels — binary only</li></ul></div>",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 12,
      "title": "Image Types Overview",
      "readingTime": "2 min",
      "content": "<div class=\"highlight\"><h4>Three Common Image Types</h4></div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/image_types_comparison.svg\" alt=\"Image Types\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"two-column\"><div class=\"column\"><ul><li><strong>Binary:</strong> 1-bit, 2 values</li><li><strong>Grayscale:</strong> 8-bit, 256 levels</li></ul></div><div class=\"column\"><ul><li><strong>Color:</strong> 24-bit RGB</li><li>3 channels × 8 bits each</li></ul></div></div>",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 13,
      "title": "Binary Images",
      "readingTime": "2 min",
      "content": "<div class=\"definition\"><strong>Binary Image:</strong> Only two values — 0 (black) or 1 (white).</div><div class=\"two-column\"><div class=\"column\"><h4>Properties</h4><ul><li>1 bit per pixel</li><li>Values: {0, 255}</li><li>Simplest image type</li></ul></div><div class=\"column\"><h4>Applications</h4><ul><li>Document scanning</li><li>Masks and regions</li><li>Morphological operations</li></ul></div></div><div class=\"highlight\"><h4>Creating Binary Images</h4><pre><code># Thresholding\nbinary = (gray > 128).astype(np.uint8) * 255</code></pre></div>",
      "hasVisualization": false,
      "knowledgeCheck": null
    },
    {
      "id": 14,
      "title": "Grayscale Images",
      "readingTime": "2 min",
      "content": "<div class=\"definition\"><strong>Grayscale Image:</strong> 256 intensity levels from black (0) to white (255).</div><div class=\"two-column\"><div class=\"column\"><h4>Properties</h4><ul><li>8 bits per pixel</li><li>1 channel</li><li>Values: 0-255</li></ul></div><div class=\"column\"><h4>Memory</h4><p>$$\\text{Size} = W \\times H \\text{ bytes}$$</p><p>Example: 640×480 = 307.2 KB</p></div></div><div class=\"highlight\"><h4>RGB to Grayscale (Luminosity)</h4><p>$$Y = 0.299R + 0.587G + 0.114B$$</p></div>",
      "hasVisualization": false,
      "knowledgeCheck": {
        "question": "Why are the coefficients in the luminosity formula different?",
        "answer": "Human eyes are most sensitive to green light, less to red, and least to blue. The coefficients (0.299, 0.587, 0.114) weight each channel according to perceived brightness."
      }
    },
    {
      "id": 15,
      "title": "Color Images (RGB)",
      "readingTime": "2 min",
      "content": "<div class=\"definition\"><strong>RGB Color Image:</strong> Three channels — Red, Green, Blue — each with 8 bits.</div><div class=\"two-column\"><div class=\"column\"><h4>Properties</h4><ul><li>24 bits per pixel</li><li>3 channels</li><li>16.7 million colors</li></ul></div><div class=\"column\"><h4>Memory</h4><p>$$\\text{Size} = W \\times H \\times 3$$</p><p>Example: 640×480 = 921.6 KB</p></div></div><div class=\"highlight\"><h4>Accessing Channels</h4><pre><code>R = image[:, :, 0]\nG = image[:, :, 1]\nB = image[:, :, 2]</code></pre></div>",
      "hasVisualization": false,
      "knowledgeCheck": null
    },
    {
      "id": 16,
      "title": "RGB Color Model",
      "readingTime": "2 min",
      "content": "<div class=\"key-point\"><strong>RGB:</strong> Additive color mixing — combining light.</div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/rgb_color_model.svg\" alt=\"RGB Model\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"two-column\"><div class=\"column\"><h4>Color Mixing</h4><ul><li>R + G = Yellow</li><li>G + B = Cyan</li><li>R + B = Magenta</li><li>R + G + B = White</li></ul></div><div class=\"column\"><h4>Pure Colors</h4><ul><li>Red: (255, 0, 0)</li><li>Green: (0, 255, 0)</li><li>Blue: (0, 0, 255)</li></ul></div></div>",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 17,
      "title": "HSV Color Model",
      "readingTime": "3 min",
      "content": "<div class=\"definition\"><strong>HSV:</strong> Hue, Saturation, Value — more intuitive for humans.</div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/hsv_color_model.svg\" alt=\"HSV Model\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"two-column\"><div class=\"column\"><h4>Components</h4><ul><li><strong>H (Hue):</strong> Color type (0-360°)</li><li><strong>S (Saturation):</strong> Color purity (0-100%)</li><li><strong>V (Value):</strong> Brightness (0-100%)</li></ul></div><div class=\"column\"><h4>Advantages</h4><ul><li>Intuitive color selection</li><li>Better for thresholding</li><li>Separates luminance from color</li></ul></div></div>",
      "hasVisualization": true,
      "knowledgeCheck": {
        "question": "When would you use HSV instead of RGB?",
        "answer": "HSV is better for color-based segmentation (e.g., detecting red objects) because you can threshold on Hue regardless of lighting (Value). In RGB, shadows and highlights change all three channels."
      }
    },
    {
      "id": 18,
      "title": "Color Space Conversion",
      "readingTime": "2 min",
      "content": "<div class=\"key-point\">Converting between color spaces is essential for many image processing tasks.</div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/color_space_conversion.svg\" alt=\"Color Conversion\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"highlight\"><h4>OpenCV Conversion</h4><pre><code>import cv2\n\n# BGR to HSV\nhsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n# BGR to Grayscale\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</code></pre></div>",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 19,
      "title": "Bit Depth & Storage",
      "readingTime": "2 min",
      "content": "<div class=\"key-point\">Higher bit depth = better quality but larger file size.</div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/bit_depth_detailed.svg\" alt=\"Bit Depth\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"warning\"><strong>Trade-off:</strong> Always balance quality requirements against storage and processing constraints.</div>",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 20,
      "title": "Memory Calculation",
      "readingTime": "2 min",
      "content": "<div class=\"definition\"><strong>Uncompressed Image Size:</strong></div><div class=\"math-block\">$$\\text{Bytes} = \\text{Width} \\times \\text{Height} \\times \\frac{\\text{Bits per Pixel}}{8}$$</div><img src=\"/static/images/courses/cmsc178ip/module-01/svg/memory_calculation_table.svg\" alt=\"Memory Table\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"highlight\"><h4>Examples</h4><ul><li><strong>1920×1080 Grayscale:</strong> 2.07 MB</li><li><strong>1920×1080 RGB:</strong> 6.22 MB</li><li><strong>4K RGB:</strong> 24.88 MB</li></ul></div>",
      "hasVisualization": true,
      "knowledgeCheck": {
        "question": "Calculate the size of a 4K (3840×2160) RGBA image with 8 bits per channel.",
        "answer": "Size = 3840 × 2160 × 4 bytes = 33,177,600 bytes ≈ 31.64 MB (uncompressed)"
      }
    },
    {
      "id": 21,
      "title": "Quality vs Storage Trade-off",
      "readingTime": "2 min",
      "content": "<img src=\"/static/images/courses/cmsc178ip/module-01/svg/quality_size_tradeoff.svg\" alt=\"Quality vs Size\" style=\"max-width: 100%; border-radius: 8px;\"><div class=\"two-column\"><div class=\"column\"><h4>When to Use High Bit Depth</h4><ul><li>Medical imaging</li><li>Scientific photography</li><li>Professional editing</li></ul></div><div class=\"column\"><h4>When to Use Low Bit Depth</h4><ul><li>Web images</li><li>Mobile apps</li><li>Real-time video</li></ul></div></div>",
      "hasVisualization": true,
      "knowledgeCheck": null
    },
    {
      "id": 22,
      "title": "Summary",
      "readingTime": "1 min",
      "content": "<div class=\"highlight\"><h4>Key Takeaways</h4><ol><li><strong>Digital images</strong> are 2D arrays of discrete pixel values</li><li><strong>Sampling</strong> determines spatial resolution (number of pixels)</li><li><strong>Quantization</strong> determines intensity levels (bit depth)</li><li><strong>Image types:</strong> Binary (1-bit), Grayscale (8-bit), Color (24-bit)</li><li><strong>Color models:</strong> RGB (additive) vs HSV (intuitive)</li><li><strong>Memory:</strong> Width × Height × Channels × Bits/8</li></ol></div><div class=\"key-point\"><strong>Next:</strong> Module 2 — Storage and Compression</div>",
      "hasVisualization": false,
      "knowledgeCheck": null
    }
  ]
}
